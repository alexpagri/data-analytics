{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_con import DatabaseConnection\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.widgets import Slider\n",
    "import scipy.stats\n",
    "from matplotlib import ticker\n",
    "import numpy as np\n",
    "from matplotlib import rc\n",
    "from fitter import get_distributions\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DatabaseConnection() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT two.fn, AVG(two.ve), MAX(two.ve), MAX(a1.accel), MIN(d1.accel), CASE WHEN AVG(two.ve) < 4.3638 THEN 0 ELSE CASE WHEN AVG(two.ve) < 5.6694 THEN 1 ELSE 2 END END FROM (\n",
    "        SELECT one.fn as fn, unnest(one.t) as ts, unnest(one.v) as ve FROM (\n",
    "        SELECT filename as fn, timestamps as t, distances as d, velos as v, (((ST_Points(geom::geometry))::json) -> 'coordinates') as pts from ride\n",
    "        ) as one\n",
    "        ) as two LEFT JOIN accels a1 ON (two.fn = a1.filename AND two.ts = a1.timestamp AND a1.accel >= 0)\n",
    "                 LEFT JOIN accels d1 ON (two.fn = d1.filename AND two.ts = d1.timestamp AND d1.accel < 0)\n",
    "                 WHERE two.ve > 0.2 AND two.ve != 'NaN' AND two.ve < 15 GROUP BY two.fn\n",
    "\n",
    "    \"\"\")\n",
    "    objs = cur.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_all = pd.DataFrame(objs, columns=['file', 'avg_speed', 'max_speed', 'max_accel', 'max_decel', 'group'])\n",
    "print(pdf_all.info)\n",
    "\n",
    "pdf_avg_all = pdf_all[['file', 'avg_speed']].sort_values('avg_speed').reset_index()\n",
    "pdf_max_all = pdf_all[['file', 'max_speed']].sort_values('max_speed').reset_index()\n",
    "pdf_acc_all = pdf_all.query('max_accel >= 0.3')[['file', 'max_accel']].sort_values('max_accel').reset_index()\n",
    "pdf_dec_all = pdf_all.query('max_decel < -0.1')[['file', 'max_decel']].sort_values('max_decel').reset_index()\n",
    "\n",
    "pdf_avg_0 = pdf_all.query('group == 0')[['file', 'avg_speed']].sort_values('avg_speed').reset_index()\n",
    "pdf_max_0 = pdf_all.query('group == 0')[['file', 'max_speed']].sort_values('max_speed').reset_index()\n",
    "pdf_acc_0 = pdf_all.query('group == 0 and max_accel >= 0.3')[['file', 'max_accel']].sort_values('max_accel').reset_index()\n",
    "pdf_dec_0 = pdf_all.query('group == 0 and max_decel < -0.1')[['file', 'max_decel']].sort_values('max_decel').reset_index()\n",
    "\n",
    "pdf_avg_1 = pdf_all.query('group == 1')[['file', 'avg_speed']].sort_values('avg_speed').reset_index()\n",
    "pdf_max_1 = pdf_all.query('group == 1')[['file', 'max_speed']].sort_values('max_speed').reset_index()\n",
    "pdf_acc_1 = pdf_all.query('group == 1 and max_accel >= 0.3')[['file', 'max_accel']].sort_values('max_accel').reset_index()\n",
    "pdf_dec_1 = pdf_all.query('group == 1 and max_decel < -0.1')[['file', 'max_decel']].sort_values('max_decel').reset_index()\n",
    "\n",
    "pdf_avg_2 = pdf_all.query('group == 2')[['file', 'avg_speed']].sort_values('avg_speed').reset_index()\n",
    "pdf_max_2 = pdf_all.query('group == 2')[['file', 'max_speed']].sort_values('max_speed').reset_index()\n",
    "pdf_acc_2 = pdf_all.query('group == 2 and max_accel >= 0.3')[['file', 'max_accel']].sort_values('max_accel').reset_index()\n",
    "pdf_dec_2 = pdf_all.query('group == 2 and max_decel < -0.1')[['file', 'max_decel']].sort_values('max_decel').reset_index()\n",
    "\n",
    "b1 = 15.71#3.6 * pdf_avg.iloc[int(0.25 * len(pdf_avg))]['avg_speed']\n",
    "b2 = 20.41#3.6 * pdf_avg.iloc[int(0.75 * len(pdf_avg))]['avg_speed']\n",
    "def plot_graph(pdf_local: pd.Series, label_name: str, vlines: bool, n_bins:int, density:bool, x_lim_0: float, x_lim_1: float, y_lim_0: float, y_lim_1: float):\n",
    "    # mn, mx = plt.xlim()\n",
    "    # plt.hist(pdf_local * 3.6, n_bins, range=(mn, mx), density=False, histtype='step')\n",
    "    # plt.hist(pdf_local, n_bins, range=(mn, mx), density=False, histtype='step', label=label_name)\n",
    "\n",
    "    rc('font', **{'family': 'serif', 'serif': ['Computer Modern'], 'size': 16})\n",
    "    rc('text', usetex=True)\n",
    "    plt.hist(pdf_local, bins=n_bins, density=density, label=label_name, histtype='step')\n",
    "\n",
    "    plt.xlim(x_lim_0, x_lim_1)\n",
    "    plt.ylim(y_lim_0, y_lim_1)\n",
    "\n",
    "    # kde_xs = np.linspace(mn, mx, 200)\n",
    "    # kde_avg = scipy.stats.gaussian_kde(pdf_local)#put data in linear regression -> plot formula\n",
    "    # plt.plot(kde_xs, ((mx - mn) / n_bins * len(pdf_local)) * kde_avg.pdf(kde_xs), label=label_name)\n",
    "    if vlines:\n",
    "        plt.vlines([pdf_local.iloc[int(0.25 * len(pdf_local))], pdf_local.iloc[int(0.75 * len(pdf_local))]], 0, 10000, colors='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rides after importing\n",
    "with DatabaseConnection() as cur:\n",
    "    cur.execute(\"\"\" SELECT COUNT(*) FROM ride \"\"\")\n",
    "    number_of_rides_response = cur.fetchall()\n",
    "\n",
    "print(\"number of all rides in \\\"ride\\\" table:{}\".format(number_of_rides_response[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg speed of all rides in m/s\n",
    "fig = plt.figure(figsize=[20, 10])\n",
    "\n",
    "ax = plt.axes()\n",
    "# ax.grid()\n",
    "# ax.xaxis.set_major_locator(ticker.LinearLocator(numticks=30))\n",
    "ax.set_ylabel('Rides')\n",
    "ax.set_xlabel('Avg Speed (m/s)')\n",
    "# plot_graph(pdf_avg_0['avg_speed'], \"Slow rides (first 25%)\", False, 400, False, 1.3, 7.9, 0, 500)\n",
    "# plot_graph(pdf_avg_1['avg_speed'], \"Medium rides (middle 50%)\", False, 200, False, 1.3, 7.9, 0, 500)\n",
    "# plot_graph(pdf_avg_2['avg_speed'], \"Fast rides (last 25%)\", False, 400, False, 1.3, 7.9, 0, 500)\n",
    "plot_graph(pdf_avg_all['avg_speed'], \"All rides\", True, 200, True, 1.3, 7.9, 0, 0.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max speed of all groups in m/s\n",
    "fig = plt.figure(figsize=[20, 10])\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.grid()\n",
    "ax.xaxis.set_major_locator(ticker.LinearLocator(numticks=30))\n",
    "ax.set_ylabel('Rides')\n",
    "ax.set_xlabel('Max Speed (m/s)')\n",
    "\n",
    "#plot_graph(pdf_avg_0['avg_speed'], \"Group 0\", False)\n",
    "plot_graph(pdf_max_0['max_speed'], \"Group 0\", False, 200, False, 0, 15, 0, 800)\n",
    "\n",
    "#plot_graph(pdf_avg_1['avg_speed'], \"Group 1\", False)\n",
    "plot_graph(pdf_max_1['max_speed'], \"Group 1\", False, 200, False, 0, 15, 0, 800)\n",
    "\n",
    "#plot_graph(pdf_avg_2['avg_speed'], \"Group 2\", False)\n",
    "plot_graph(pdf_max_2['max_speed'], \"Group 2\", False, 200, False, 0, 15, 0, 800)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max acceleration of all groups in m/s\n",
    "fig = plt.figure(figsize=[20, 10])\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.grid()\n",
    "ax.xaxis.set_major_locator(ticker.LinearLocator(numticks=30))\n",
    "ax.set_ylabel('Rides')\n",
    "ax.set_xlabel('Max Acceleration (m/s²)')\n",
    "plt.xlim(0, 2)\n",
    "\n",
    "#plot_graph(pdf_avg_0['avg_speed'], \"Group 0\", False)\n",
    "plot_graph(pdf_acc_0['max_accel'], \"Group 0\", False, 400, False, 0, 2, 0, 450)\n",
    "\n",
    "#plot_graph(pdf_avg_1['avg_speed'], \"Group 1\", False)\n",
    "plot_graph(pdf_acc_1['max_accel'], \"Group 1\", False, 400, False, 0, 2, 0, 450)\n",
    "\n",
    "#plot_graph(pdf_avg_2['avg_speed'], \"Group 2\", False)\n",
    "plot_graph(pdf_acc_2['max_accel'], \"Group 2\", False, 400, False, 0, 2, 0, 450)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max deceleration of all groups combined in m/s\n",
    "fig = plt.figure(figsize=[20, 10])\n",
    "\n",
    "ax = plt.axes()\n",
    "# ax.grid()\n",
    "# ax.xaxis.set_major_locator(ticker.LinearLocator(numticks=30))\n",
    "ax.set_ylabel('Rides')\n",
    "ax.set_xlabel('Avg Deceleration (m/s²)')\n",
    "# plt.xlim(-1.2, 0)\n",
    "\n",
    "#plot_graph(pdf_avg_0['avg_speed'], \"Group 0\", False)\n",
    "plot_graph(pdf_dec_all['max_decel'], \"All Groups\", False, 200, False, -1.2, 0, 0, 2450)\n",
    "\n",
    "#plot_graph(pdf_avg_1['avg_speed'], \"Group 1\", False)\n",
    "#plot_graph(pdf_acc_1['max_accel'], \"Group 1\", False)\n",
    "\n",
    "#plot_graph(pdf_avg_2['avg_speed'], \"Group 2\", False)\n",
    "#plot_graph(pdf_acc_2['max_accel'], \"Group 2\", False)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max speed of all rides in m/s\n",
    "fig = plt.figure(figsize=[20, 10])\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.grid()\n",
    "ax.xaxis.set_major_locator(ticker.LinearLocator(numticks=30))\n",
    "ax.set_ylabel('Rides')\n",
    "ax.set_xlabel('Max Speed (m/s)')\n",
    "\n",
    "#plot_graph(pdf_avg_0['avg_speed'], \"Group 0\", False)\n",
    "plot_graph(pdf_all['max_speed'], \"All Rides\", False, 200, False, 0, 15, 0, 1000)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max acceleration of all rides in m/s\n",
    "fig = plt.figure(figsize=[20, 10])\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.grid()\n",
    "ax.xaxis.set_major_locator(ticker.LinearLocator(numticks=30))\n",
    "ax.set_ylabel('Rides')\n",
    "ax.set_xlabel('Max Acceleration (m/s²)')\n",
    "\n",
    "#plot_graph(pdf_avg_0['avg_speed'], \"Group 0\", False)\n",
    "plot_graph(pdf_all['max_accel'], \"All Rides\", False, 200, False, 0, 2.6, 0, 1200)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max deceleration of all rides in m/s\n",
    "fig = plt.figure(figsize=[20, 10])\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.grid()\n",
    "ax.xaxis.set_major_locator(ticker.LinearLocator(numticks=30))\n",
    "ax.set_ylabel('Rides')\n",
    "ax.set_xlabel('Max Deceleration (m/s²)')\n",
    "\n",
    "#plot_graph(pdf_avg_0['avg_speed'], \"Group 0\", False)\n",
    "plot_graph(pdf_all['max_decel'], \"All Rides\", False, 200, False, -1.5, 0, 0, 2000)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best distribution for group 0 v_max\n",
    "\n",
    "list_of_dists_for_v_max = ['beta', 'betaprime', 'bradford', 'burr', 'burr12', 'cauchy', 'chi', 'chi2', 'cosine', 'dgamma', 'dweibull', 'erlang', 'expon', 'exponnorm', 'exponweib', 'exponpow', 'f', 'fatiguelife', 'fisk', 'foldcauchy', 'foldnorm', 'frechet_r', 'frechet_l', 'genlogistic', 'genpareto', 'gennorm', 'genexpon', 'genextreme', 'gausshyper', 'gamma', 'gengamma', 'genhalflogistic', 'gilbrat', 'gompertz', 'gumbel_r', 'gumbel_l', 'halfcauchy', 'halflogistic', 'halfnorm', 'halfgennorm', 'hypsecant', 'invgamma', 'invgauss', 'invweibull', 'johnsonsb', 'johnsonsu', 'kstwobign', 'laplace', 'levy', 'levy_l', 'logistic', 'loggamma', 'loglaplace', 'lognorm', 'lomax', 'maxwell', 'mielke', 'nakagami', 'ncx2', 'ncf', 'nct', 'norm', 'pareto', 'pearson3', 'powerlaw', 'powerlognorm', 'powernorm', 'rdist', 'reciprocal', 'rayleigh', 'rice', 'recipinvgauss', 'semicircular', 't', 'triang', 'truncexpon', 'truncnorm', 'tukeylambda', 'uniform', 'vonmises', 'vonmises_line', 'wald', 'weibull_min', 'weibull_max']\n",
    "\n",
    "results=[]\n",
    "for i in list_of_dists_for_v_max:\n",
    "    try:\n",
    "        dist = getattr(scipy.stats, i)\n",
    "        param = dist.fit(pdf_max_0['max_speed'])\n",
    "        a0 = scipy.stats.kstest(pdf_max_0['max_speed'], i, args=param)\n",
    "        # print(\"{}: statistic={}, pvalue={}\".format(i, a[0], a[1]))\n",
    "        results.append((i, a0[0], a0[1], param))\n",
    "    except ValueError as e:\n",
    "        print(\"      error type {} for {}\".format(e,i))\n",
    "        continue\n",
    "\n",
    "results.sort(key=lambda x:float(x[2]), reverse=True)\n",
    "print(\"============================================\\n\")\n",
    "for j in results:\n",
    "    print(\"{}: statistic={}, pvalue={}, param={}\".format(j[0], j[1], j[2], j[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best distribution for group 1 v_max\n",
    "\n",
    "results=[]\n",
    "for i in list_of_dists_for_v_max:\n",
    "    try:\n",
    "        dist = getattr(scipy.stats, i)\n",
    "        param = dist.fit(pdf_max_1['max_speed'])\n",
    "        a0 = scipy.stats.kstest(pdf_max_1['max_speed'], i, args=param)\n",
    "        # print(\"{}: statistic={}, pvalue={}\".format(i, a[0], a[1]))\n",
    "        results.append((i, a0[0], a0[1], param))\n",
    "    except ValueError as e:\n",
    "        print(\"      error type {} for {}\".format(e,i))\n",
    "        continue\n",
    "\n",
    "results.sort(key=lambda x:float(x[2]), reverse=True)\n",
    "print(\"============================================\\n\")\n",
    "for j in results:\n",
    "    print(\"{}: statistic={}, pvalue={}, param={}\".format(j[0], j[1], j[2], j[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best distribution for group 2 v_max\n",
    "\n",
    "results=[]\n",
    "for i in list_of_dists_for_v_max:\n",
    "    try:\n",
    "        dist = getattr(scipy.stats, i)\n",
    "        param = dist.fit(pdf_max_2['max_speed'])\n",
    "        a0 = scipy.stats.kstest(pdf_max_2['max_speed'], i, args=param)\n",
    "        # print(\"{}: statistic={}, pvalue={}\".format(i, a[0], a[1]))\n",
    "        results.append((i, a0[0], a0[1], param))\n",
    "    except ValueError as e:\n",
    "        print(\"      error type {} for {}\".format(e,i))\n",
    "        continue\n",
    "\n",
    "results.sort(key=lambda x:float(x[2]), reverse=True)\n",
    "print(\"============================================\\n\")\n",
    "for j in results:\n",
    "    print(\"{}: statistic={}, pvalue={}, param={}\".format(j[0], j[1], j[2], j[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best distribution for group 0 a_max\n",
    "\n",
    "list_of_dists_for_a_max = ['alpha', 'anglit', 'arcsine', 'beta', 'betaprime', 'bradford', 'burr', 'burr12', 'cauchy', 'chi', 'chi2', 'cosine', 'dgamma', 'dweibull', 'erlang', 'expon', 'exponnorm', 'exponweib', 'exponpow', 'f', 'fatiguelife', 'fisk', 'foldcauchy', 'foldnorm', 'frechet_r', 'frechet_l', 'genlogistic', 'genpareto', 'gennorm', 'genexpon', 'genextreme', 'gausshyper', 'gamma', 'gengamma', 'genhalflogistic', 'gilbrat', 'gompertz', 'gumbel_r', 'gumbel_l', 'halfcauchy', 'halflogistic', 'halfnorm', 'halfgennorm', 'hypsecant', 'invgamma', 'invgauss', 'invweibull', 'johnsonsb', 'johnsonsu', 'kstwobign', 'laplace', 'levy', 'levy_l', 'logistic', 'loggamma', 'loglaplace', 'lognorm', 'lomax', 'maxwell', 'mielke', 'nakagami', 'ncx2', 'ncf', 'nct', 'norm', 'pareto', 'pearson3', 'powerlaw', 'powerlognorm', 'powernorm', 'rdist', 'reciprocal', 'rayleigh', 'rice', 'recipinvgauss', 'semicircular', 't', 'triang', 'truncexpon', 'truncnorm', 'tukeylambda', 'uniform', 'vonmises', 'vonmises_line', 'wald', 'weibull_min', 'weibull_max']\n",
    "results=[]\n",
    "for i in list_of_dists_for_a_max:\n",
    "    try:\n",
    "        dist = getattr(scipy.stats, i)\n",
    "        param = dist.fit(pdf_acc_0['max_accel'])\n",
    "        a0 = scipy.stats.kstest(pdf_acc_0['max_accel'], i, args=param)\n",
    "        # print(\"{}: statistic={}, pvalue={}\".format(i, a[0], a[1]))\n",
    "        results.append((i, a0[0], a0[1], param))\n",
    "    except ValueError as e:\n",
    "        print(\"      error type {} for {}\".format(e,i))\n",
    "        continue\n",
    "\n",
    "results.sort(key=lambda x:float(x[2]), reverse=True)\n",
    "print(\"============================================\\n\")\n",
    "for j in results:\n",
    "    print(\"{}: statistic={}, pvalue={}, param={}\".format(j[0], j[1], j[2], j[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best distribution for group 1 a_max\n",
    "\n",
    "results=[]\n",
    "for i in list_of_dists_for_a_max:\n",
    "    try:\n",
    "        dist = getattr(scipy.stats, i)\n",
    "        param = dist.fit(pdf_acc_1['max_accel'])\n",
    "        a0 = scipy.stats.kstest(pdf_acc_1['max_accel'], i, args=param)\n",
    "        # print(\"{}: statistic={}, pvalue={}\".format(i, a[0], a[1]))\n",
    "        results.append((i, a0[0], a0[1], param))\n",
    "    except ValueError as e:\n",
    "        print(\"      error type {} for {}\".format(e,i))\n",
    "        continue\n",
    "\n",
    "results.sort(key=lambda x:float(x[2]), reverse=True)\n",
    "print(\"============================================\\n\")\n",
    "for j in results:\n",
    "    print(\"{}: statistic={}, pvalue={}, param={}\".format(j[0], j[1], j[2], j[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best distribution for group 2 a_max\n",
    "results=[]\n",
    "for i in list_of_dists_for_a_max:\n",
    "    try:\n",
    "        dist = getattr(scipy.stats, i)\n",
    "        param = dist.fit(pdf_acc_2['max_accel'])\n",
    "        a0 = scipy.stats.kstest(pdf_acc_2['max_accel'], i, args=param)\n",
    "        # print(\"{}: statistic={}, pvalue={}\".format(i, a[0], a[1]))\n",
    "        results.append((i, a0[0], a0[1], param))\n",
    "    except ValueError as e:\n",
    "        print(\"      error type {} for {}\".format(e,i))\n",
    "        continue\n",
    "\n",
    "results.sort(key=lambda x:float(x[2]), reverse=True)\n",
    "print(\"============================================\\n\")\n",
    "for j in results:\n",
    "    print(\"{}: statistic={}, pvalue={}, param={}\".format(j[0], j[1], j[2], j[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best distribution for all groups d_max\n",
    "list_of_dists_for_d_max = ['powernorm','norm','exponnorm','beta','betaprime','bradford','burr','burr12','cauchy','chi','chi2','cosine','dgamma','dweibull','erlang','expon','exponnorm','exponweib','exponpow','f','fatiguelife','fisk','foldcauchy','foldnorm','frechet_r','frechet_l','genlogistic','genpareto','gennorm','genexpon','genextreme','gausshyper','gamma','gengamma','genhalflogistic','gilbrat','gompertz','gumbel_r','gumbel_l','halfcauchy','halflogistic','halfnorm','halfgennorm','hypsecant','invgamma','invgauss','invweibull','johnsonsb','johnsonsu','kstwobign','laplace','levy','levy_l','logistic','loggamma','loglaplace','lognorm','lomax','maxwell','mielke','nakagami','ncx2','ncf','nct','norm','pareto','pearson3','powerlaw','powerlognorm','powernorm','rdist','reciprocal','rayleigh','rice','recipinvgauss','semicircular','t','triang','truncexpon','truncnorm','tukeylambda','uniform','vonmises','vonmises_line','wald','weibull_min','weibull_max']\n",
    "results=[]\n",
    "\n",
    "for i in list_of_dists_for_d_max:\n",
    "    try:\n",
    "        dist = getattr(scipy.stats, i)\n",
    "        param = dist.fit(pdf_dec_all['max_decel'])\n",
    "        a0 = scipy.stats.kstest(pdf_dec_all['max_decel'], i, args=param)\n",
    "        # print(\"{}: statistic={}, pvalue={}\".format(i, a[0], a[1]))\n",
    "        results.append((i, a0[0], a0[1], param))\n",
    "    except ValueError as e:\n",
    "        print(\"      error type {} for {}\".format(e,i))\n",
    "        continue\n",
    "\n",
    "results.sort(key=lambda x:float(x[2]), reverse=True)\n",
    "print(\"============================================\\n\")\n",
    "for j in results:\n",
    "    print(\"{}: statistic={}, pvalue={}, param={}\".format(j[0], j[1], j[2], j[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots for v_max\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern'], 'size': 16})\n",
    "rc('text', usetex=True)\n",
    "plt.hist(pdf_max_0['max_speed'], bins=65, density=True, label=r'$^{s}v_{max}^{SimRa}$', alpha=0.3)\n",
    "plt.hist(pdf_max_1['max_speed'], bins=65, density=True, label=r'$^{m}v_{max}^{SimRa}$', alpha=0.3)\n",
    "plt.hist(pdf_max_2['max_speed'], bins=65, density=True, label=r'$^{f}v_{max}^{SimRa}$', alpha=0.3)\n",
    "\n",
    "# plt.hist(pdf_max_0['max_speed'], bins=65, density=True, label=r'$^{s}v_{max}^{SimRa}$', histtype='step')\n",
    "# plt.hist(pdf_max_1['max_speed'], bins=65, density=True, label=r'$^{m}v_{max}^{SimRa}$', histtype='step')\n",
    "# plt.hist(pdf_max_2['max_speed'], bins=65, density=True, label=r'$^{f}v_{max}^{SimRa}$', histtype='step')\n",
    "\n",
    "a0, b0, c0, d0 = scipy.stats.nct.fit(pdf_max_0['max_speed']) # 0 v_max -> nct (4 params)\n",
    "a1, b1, c1 = scipy.stats.fisk.fit(pdf_max_1['max_speed']) # 1 v_max -> fisk (3 params)\n",
    "a2, b2, c2 = scipy.stats.exponnorm.fit(pdf_max_2['max_speed']) # 2 v_max -> exponnorm (3 params)\n",
    "x = np.linspace(0, 16, 1000)\n",
    "y0 = scipy.stats.nct.pdf(x, a0, b0, c0, d0)\n",
    "y1 = scipy.stats.fisk.pdf(x, a1, b1, c1)\n",
    "y2 = scipy.stats.exponnorm.pdf(x, a2, b2, c2)\n",
    "# Noncentral t-distribution\n",
    "plt.plot(x, y0, linewidth=3, label='NCT(' + r'$^{s}v_{max}; \\Phi^*$' + ')')\n",
    "# The Fisk distribution is also known as the log-logistic distribution.\n",
    "plt.plot(x, y1, linewidth=3, label='LogLog(' + r'$^{m}v_{max}; \\Phi^*$' + ')')\n",
    "# exponentially modified Gaussian distribution (EMG)\n",
    "plt.plot(x, y2, linewidth=3, label='EMG(' + r'$^{f}v_{max}; \\Phi^*$' + ')')\n",
    "plt.xlabel(r'$v_{max}$ in m/s')\n",
    "plt.ylabel('Relative frequency')\n",
    "plt.vlines(5.56, 0, 4, colors='r', linewidth=3, label=r'$v_{max}^{SUMO}$')\n",
    "plt.xlim(1, 15)\n",
    "plt.ylim(0, 0.45)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"images/velo_max_all_groups.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# print(scipy.stats.nct.cdf(5.56, a0, b0, loc0, scale0))\n",
    "# print(scipy.stats.nct.cdf(25 / 3.6, a0, b0, loc0, scale0)) #\n",
    "#\n",
    "# print(scipy.stats.kstest(pdf_max_0['max_speed'], 'nct', args=(a0, b0, loc0, scale0)))\n",
    "# print(a0, b0, loc0, scale0)\n",
    "# print(scipy.stats.nct.ppf(0.05, a0, b0, loc0, scale0))\n",
    "# print(scipy.stats.nct.ppf(0.95, a0, b0, loc0, scale0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots for a_max\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern'], 'size': 16})\n",
    "rc('text', usetex=True)\n",
    "plt.hist(pdf_acc_0['max_accel'], bins=65, density=True, label=r'$^{s}a_{max}^{SimRa}$', alpha=0.3)\n",
    "plt.hist(pdf_acc_1['max_accel'], bins=65, density=True, label=r'$^{m}a_{max}^{SimRa}$', alpha=0.3)\n",
    "plt.hist(pdf_acc_2['max_accel'], bins=65, density=True, label=r'$^{f}a_{max}^{SimRa}$', alpha=0.3)\n",
    "\n",
    "# johnsonsu: statistic=0.025183421872094713, pvalue=1.91179659489062e-06, param=(0.0770684494542768, 1.3393758794499697, 0.7266280940763412, 0.309608761301854)\n",
    "a0, b0, c0, d0 = scipy.stats.johnsonsu.fit(pdf_acc_0['max_accel']) # 0 a_max -> johnsonsu (4 params)\n",
    "# johnsonsu: statistic=0.022065300180767536, pvalue=8.035176850138819e-10, param=(0.20920923092582538, 1.2809999987024459, 0.9796819148057333, 0.2961165230998936)\n",
    "a1, b1, c1, d1 = scipy.stats.johnsonsu.fit(pdf_acc_1['max_accel']) # 1 a_max -> johnsonsu (4 params)\n",
    "# johnsonsu: statistic=0.025572129061473874, pvalue=1.8394759102960317e-06, param=(0.3159537912047191, 1.1750478235384183, 1.1777544947250909, 0.30653498982942246)\n",
    "a2, b2, c2, d2 = scipy.stats.johnsonsu.fit(pdf_acc_2['max_accel']) # 2 a_max -> johnsonsu (4 params)\n",
    "x = np.linspace(0, 16, 1000)\n",
    "y0 = scipy.stats.johnsonsu.pdf(x, a0, b0, c0, d0)\n",
    "y1 = scipy.stats.johnsonsu.pdf(x, a1, b1, c1, d1)\n",
    "y2 = scipy.stats.johnsonsu.pdf(x, a2, b2, c2, d2)\n",
    "# Laplace\n",
    "plt.plot(x, y0, linewidth=3, label='JSU(' + r'$^{s}a_{max}; \\Phi^*$' + ')')\n",
    "# Johnson SU\n",
    "plt.plot(x, y1, linewidth=3, label='JSU(' + r'$^{m}a_{max}; \\Phi^*$' + ')')\n",
    "plt.plot(x, y2, linewidth=3, label='JSU(' + r'$^{f}a_{max}; \\Phi^*$' + ')')\n",
    "plt.xlabel(r'$a_{max}$ in m/s²')\n",
    "plt.ylabel('Relative frequency')\n",
    "plt.vlines(1.2, 0, 4, colors='r', linewidth=3, label=r'$v_{max}^{SUMO}$')\n",
    "plt.xlim(0, 2)\n",
    "plt.ylim(0, 1.8)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"images/accel_max_all_groups.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# print(scipy.stats.nct.cdf(5.56, a0, b0, loc0, scale0))\n",
    "# print(scipy.stats.nct.cdf(25 / 3.6, a0, b0, loc0, scale0)) #\n",
    "#\n",
    "# print(scipy.stats.kstest(pdf_max_0['max_speed'], 'nct', args=(a0, b0, loc0, scale0)))\n",
    "# print(a0, b0, loc0, scale0)\n",
    "# print(scipy.stats.nct.ppf(0.05, a0, b0, loc0, scale0))\n",
    "# print(scipy.stats.nct.ppf(0.95, a0, b0, loc0, scale0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots for d_max\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern'], 'size': 16})\n",
    "rc('text', usetex=True)\n",
    "# plt.hist(pdf_dec_all['max_decel'], bins=65, density=True, label=r'$d_{max}^{SimRa}$', alpha=0.3)\n",
    "plt.hist(pdf_all['max_decel'][lambda x: x < 0], bins=65, density=True, label=r'$d_{max}^{SimRa}$', alpha=0.3)\n",
    "\n",
    "\n",
    "# johnsonsu: statistic=0.044699258286050425, pvalue=1.9110272690045537e-78, param=(1.1326944850310685, 0.8918487357003242, -0.16435007411878877, 0.058605831159347296)\n",
    "# a, b, c, d = scipy.stats.johnsonsu.fit(pdf_dec_all['max_decel']) # d_max -> johnsonsu (4 params)\n",
    "a, b, c, d = scipy.stats.johnsonsu.fit(pdf_all['max_decel'][lambda x: x < 0]) # d_max -> johnsonsu (4 params)\n",
    "x = np.linspace(-2, 0, 1000)\n",
    "y = scipy.stats.johnsonsu.pdf(x, a, b, c, d)\n",
    "# Johnson SU\n",
    "plt.plot(x, y, linewidth=3, label='JSU(' + r'$d_{max}; \\Phi^*$' + ')')\n",
    "plt.xlabel(r'$d_{max}$ in m/s²')\n",
    "plt.ylabel('Relative frequency')\n",
    "plt.vlines(-3, 0, 10, colors='r', linewidth=3, label=r'$v_{max}^{SUMO}$')\n",
    "plt.xlim(-3.1, 0)\n",
    "plt.ylim(0, 4.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"images/decel_max_all.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# print(scipy.stats.nct.cdf(5.56, a0, b0, loc0, scale0))\n",
    "# print(scipy.stats.nct.cdf(25 / 3.6, a0, b0, loc0, scale0)) #\n",
    "#\n",
    "# print(scipy.stats.kstest(pdf_max_0['max_speed'], 'nct', args=(a0, b0, loc0, scale0)))\n",
    "# print(a0, b0, loc0, scale0)\n",
    "# print(scipy.stats.nct.ppf(0.05, a0, b0, loc0, scale0))\n",
    "# print(scipy.stats.nct.ppf(0.95, a0, b0, loc0, scale0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best distribution for all rides v_max\n",
    "\n",
    "list_of_dists_for_v_max = ['beta', 'betaprime', 'bradford', 'burr', 'burr12', 'cauchy', 'chi', 'chi2', 'cosine', 'dgamma', 'dweibull', 'erlang', 'expon', 'exponnorm', 'exponweib', 'exponpow', 'f', 'fatiguelife', 'fisk', 'foldcauchy', 'foldnorm', 'frechet_r', 'frechet_l', 'genlogistic', 'genpareto', 'gennorm', 'genexpon', 'genextreme', 'gausshyper', 'gamma', 'gengamma', 'genhalflogistic', 'gilbrat', 'gompertz', 'gumbel_r', 'gumbel_l', 'halfcauchy', 'halflogistic', 'halfnorm', 'halfgennorm', 'hypsecant', 'invgamma', 'invgauss', 'invweibull', 'johnsonsb', 'johnsonsu', 'kstwobign', 'laplace', 'levy', 'levy_l', 'logistic', 'loggamma', 'loglaplace', 'lognorm', 'lomax', 'maxwell', 'mielke', 'nakagami', 'ncx2', 'ncf', 'nct', 'norm', 'pareto', 'pearson3', 'powerlaw', 'powerlognorm', 'powernorm', 'rdist', 'reciprocal', 'rayleigh', 'rice', 'recipinvgauss', 'semicircular', 't', 'triang', 'truncexpon', 'truncnorm', 'tukeylambda', 'uniform', 'vonmises', 'vonmises_line', 'wald', 'weibull_min', 'weibull_max']\n",
    "\n",
    "results=[]\n",
    "for i in list_of_dists_for_v_max:\n",
    "    try:\n",
    "        dist = getattr(scipy.stats, i)\n",
    "        param = dist.fit(pdf_max_all['max_speed'])\n",
    "        a0 = scipy.stats.kstest(pdf_max_all['max_speed'], i, args=param)\n",
    "        # print(\"{}: statistic={}, pvalue={}\".format(i, a[0], a[1]))\n",
    "        results.append((i, a0[0], a0[1], param))\n",
    "    except ValueError as e:\n",
    "        print(\"      error type {} for {}\".format(e,i))\n",
    "        continue\n",
    "\n",
    "results.sort(key=lambda x:float(x[2]), reverse=True)\n",
    "print(\"============================================\\n\")\n",
    "for j in results:\n",
    "    print(\"{}: statistic={}, pvalue={}, param={}\".format(j[0], j[1], j[2], j[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Find the best distribution for all rides a_max\n",
    "\n",
    "list_of_dists_for_a_max = ['alpha', 'anglit', 'arcsine', 'beta', 'betaprime', 'bradford', 'burr', 'burr12', 'cauchy', 'chi', 'chi2', 'cosine', 'dgamma', 'dweibull', 'erlang', 'expon', 'exponnorm', 'exponweib', 'exponpow', 'f', 'fatiguelife', 'fisk', 'foldcauchy', 'foldnorm', 'frechet_r', 'frechet_l', 'genlogistic', 'genpareto', 'gennorm', 'genexpon', 'genextreme', 'gausshyper', 'gamma', 'gengamma', 'genhalflogistic', 'gilbrat', 'gompertz', 'gumbel_r', 'gumbel_l', 'halfcauchy', 'halflogistic', 'halfnorm', 'halfgennorm', 'hypsecant', 'invgamma', 'invgauss', 'invweibull', 'johnsonsb', 'johnsonsu', 'kstwobign', 'laplace', 'levy', 'levy_l', 'logistic', 'loggamma', 'loglaplace', 'lognorm', 'lomax', 'maxwell', 'mielke', 'nakagami', 'ncx2', 'ncf', 'nct', 'norm', 'pareto', 'pearson3', 'powerlaw', 'powerlognorm', 'powernorm', 'rdist', 'reciprocal', 'rayleigh', 'rice', 'recipinvgauss', 'semicircular', 't', 'triang', 'truncexpon', 'truncnorm', 'tukeylambda', 'uniform', 'vonmises', 'vonmises_line', 'wald', 'weibull_min', 'weibull_max']\n",
    "results=[]\n",
    "for i in list_of_dists_for_a_max:\n",
    "    try:\n",
    "        dist = getattr(scipy.stats, i)\n",
    "        param = dist.fit(pdf_acc_all['max_accel'])\n",
    "        a0 = scipy.stats.kstest(pdf_acc_all['max_accel'], i, args=param)\n",
    "        # print(\"{}: statistic={}, pvalue={}\".format(i, a[0], a[1]))\n",
    "        results.append((i, a0[0], a0[1], param))\n",
    "    except ValueError as e:\n",
    "        print(\"      error type {} for {}\".format(e,i))\n",
    "        continue\n",
    "\n",
    "results.sort(key=lambda x:float(x[2]), reverse=True)\n",
    "print(\"============================================\\n\")\n",
    "for j in results:\n",
    "    print(\"{}: statistic={}, pvalue={}, param={}\".format(j[0], j[1], j[2], j[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best distribution for all rides d_max\n",
    "list_of_dists_for_d_max = ['powernorm','norm','exponnorm','beta','betaprime','bradford','burr','burr12','cauchy','chi','chi2','cosine','dgamma','dweibull','erlang','expon','exponnorm','exponweib','exponpow','f','fatiguelife','fisk','foldcauchy','foldnorm','frechet_r','frechet_l','genlogistic','genpareto','gennorm','genexpon','genextreme','gausshyper','gamma','gengamma','genhalflogistic','gilbrat','gompertz','gumbel_r','gumbel_l','halfcauchy','halflogistic','halfnorm','halfgennorm','hypsecant','invgamma','invgauss','invweibull','johnsonsb','johnsonsu','kstwobign','laplace','levy','levy_l','logistic','loggamma','loglaplace','lognorm','lomax','maxwell','mielke','nakagami','ncx2','ncf','nct','norm','pareto','pearson3','powerlaw','powerlognorm','powernorm','rdist','reciprocal','rayleigh','rice','recipinvgauss','semicircular','t','triang','truncexpon','truncnorm','tukeylambda','uniform','vonmises','vonmises_line','wald','weibull_min','weibull_max']\n",
    "results=[]\n",
    "\n",
    "for i in list_of_dists_for_d_max:\n",
    "    try:\n",
    "        dist = getattr(scipy.stats, i)\n",
    "        param = dist.fit(pdf_dec_all['max_decel'])\n",
    "        a0 = scipy.stats.kstest(pdf_dec_all['max_decel'], i, args=param)\n",
    "        # print(\"{}: statistic={}, pvalue={}\".format(i, a[0], a[1]))\n",
    "        results.append((i, a0[0], a0[1], param))\n",
    "    except ValueError as e:\n",
    "        print(\"      error type {} for {}\".format(e,i))\n",
    "        continue\n",
    "\n",
    "results.sort(key=lambda x:float(x[2]), reverse=True)\n",
    "print(\"============================================\\n\")\n",
    "for j in results:\n",
    "    print(\"{}: statistic={}, pvalue={}, param={}\".format(j[0], j[1], j[2], j[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for all rides v_max\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern'], 'size': 16})\n",
    "rc('text', usetex=True)\n",
    "plt.hist(pdf_max_all['max_speed'], bins=65, density=True, label=r'$v_{max}^{SimRa}$', alpha=0.3)\n",
    "# plt.hist(pdf_max_1['max_speed'], bins=65, density=True, label=r'$^{m}v_{max}^{SimRa}$', alpha=0.3)\n",
    "# plt.hist(pdf_max_2['max_speed'], bins=65, density=True, label=r'$^{f}v_{max}^{SimRa}$', alpha=0.3)\n",
    "\n",
    "# plt.hist(pdf_max_0['max_speed'], bins=65, density=True, label=r'$^{s}v_{max}^{SimRa}$', histtype='step')\n",
    "# plt.hist(pdf_max_1['max_speed'], bins=65, density=True, label=r'$^{m}v_{max}^{SimRa}$', histtype='step')\n",
    "# plt.hist(pdf_max_2['max_speed'], bins=65, density=True, label=r'$^{f}v_{max}^{SimRa}$', histtype='step')\n",
    "\n",
    "a0, b0, c0, d0 = scipy.stats.burr.fit(pdf_max_all['max_speed']) # 0 v_max -> nct (4 params)\n",
    "# a1, b1, c1 = scipy.stats.fisk.fit(pdf_max_1['max_speed']) # 1 v_max -> fisk (3 params)\n",
    "# a2, b2, c2 = scipy.stats.exponnorm.fit(pdf_max_2['max_speed']) # 2 v_max -> exponnorm (3 params)\n",
    "x = np.linspace(0, 16, 1000)\n",
    "y0 = scipy.stats.burr.pdf(x, a0, b0, c0, d0)\n",
    "# Noncentral t-distribution\n",
    "plt.plot(x, y0, linewidth=3, label='Burr3(' + r'$^{s}v_{max}; \\Phi^*$' + ')')\n",
    "# The Fisk distribution is also known as the log-logistic distribution.\n",
    "# plt.plot(x, y1, linewidth=3, label='LogLog(' + r'$^{m}v_{max}; \\Phi^*$' + ')')\n",
    "# exponentially modified Gaussian distribution (EMG)\n",
    "# plt.plot(x, y2, linewidth=3, label='EMG(' + r'$^{f}v_{max}; \\Phi^*$' + ')')\n",
    "plt.xlabel(r'$v_{max}$ in m/s')\n",
    "plt.ylabel('Relative frequency')\n",
    "plt.vlines(5.56, 0, 4, colors='r', linewidth=3, label=r'$v_{max}^{SUMO}$')\n",
    "plt.xlim(1, 15)\n",
    "plt.ylim(0, 0.45)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"images/velo_max_all_rides.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# print(scipy.stats.nct.cdf(5.56, a0, b0, loc0, scale0))\n",
    "# print(scipy.stats.nct.cdf(25 / 3.6, a0, b0, loc0, scale0)) #\n",
    "#\n",
    "# print(scipy.stats.kstest(pdf_max_0['max_speed'], 'nct', args=(a0, b0, loc0, scale0)))\n",
    "# print(a0, b0, loc0, scale0)\n",
    "# print(scipy.stats.nct.ppf(0.05, a0, b0, loc0, scale0))\n",
    "# print(scipy.stats.nct.ppf(0.95, a0, b0, loc0, scale0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for all rides a_max\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern'], 'size': 16})\n",
    "rc('text', usetex=True)\n",
    "plt.hist(pdf_acc_all['max_accel'], bins=65, density=True, label=r'$a_{max}^{SimRa}$', alpha=0.3)\n",
    "# plt.hist(pdf_max_1['max_speed'], bins=65, density=True, label=r'$^{m}v_{max}^{SimRa}$', alpha=0.3)\n",
    "# plt.hist(pdf_max_2['max_speed'], bins=65, density=True, label=r'$^{f}v_{max}^{SimRa}$', alpha=0.3)\n",
    "\n",
    "# plt.hist(pdf_max_0['max_speed'], bins=65, density=True, label=r'$^{s}v_{max}^{SimRa}$', histtype='step')\n",
    "# plt.hist(pdf_max_1['max_speed'], bins=65, density=True, label=r'$^{m}v_{max}^{SimRa}$', histtype='step')\n",
    "# plt.hist(pdf_max_2['max_speed'], bins=65, density=True, label=r'$^{f}v_{max}^{SimRa}$', histtype='step')\n",
    "\n",
    "a0, b0, c0, d0 = scipy.stats.johnsonsu.fit(pdf_acc_all['max_accel']) # 0 v_max -> nct (4 params)\n",
    "# a1, b1, c1 = scipy.stats.fisk.fit(pdf_max_1['max_speed']) # 1 v_max -> fisk (3 params)\n",
    "# a2, b2, c2 = scipy.stats.exponnorm.fit(pdf_max_2['max_speed']) # 2 v_max -> exponnorm (3 params)\n",
    "x = np.linspace(0, 16, 1000)\n",
    "y0 = scipy.stats.johnsonsu.pdf(x, a0, b0, c0, d0)\n",
    "# Noncentral t-distribution\n",
    "plt.plot(x, y0, linewidth=3, label='JSU(' + r'$^{s}a_{max}; \\Phi^*$' + ')')\n",
    "# The Fisk distribution is also known as the log-logistic distribution.\n",
    "# plt.plot(x, y1, linewidth=3, label='LogLog(' + r'$^{m}v_{max}; \\Phi^*$' + ')')\n",
    "# exponentially modified Gaussian distribution (EMG)\n",
    "# plt.plot(x, y2, linewidth=3, label='EMG(' + r'$^{f}v_{max}; \\Phi^*$' + ')')\n",
    "plt.xlabel(r'$a_{max}$ in m/s')\n",
    "plt.ylabel('Relative frequency')\n",
    "plt.vlines(1.2, 0, 4, colors='r', linewidth=3, label=r'$a_{max}^{SUMO}$')\n",
    "plt.xlim(0, 2)\n",
    "plt.ylim(0, 1.8)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"images/acc_max_all_rides.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# print(scipy.stats.nct.cdf(5.56, a0, b0, loc0, scale0))\n",
    "# print(scipy.stats.nct.cdf(25 / 3.6, a0, b0, loc0, scale0)) #\n",
    "#\n",
    "# print(scipy.stats.kstest(pdf_max_0['max_speed'], 'nct', args=(a0, b0, loc0, scale0)))\n",
    "# print(a0, b0, loc0, scale0)\n",
    "# print(scipy.stats.nct.ppf(0.05, a0, b0, loc0, scale0))\n",
    "# print(scipy.stats.nct.ppf(0.95, a0, b0, loc0, scale0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots for d_max\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern'], 'size': 16})\n",
    "rc('text', usetex=True)\n",
    "# plt.hist(pdf_dec_all['max_decel'], bins=65, density=True, label=r'$d_{max}^{SimRa}$', alpha=0.3)\n",
    "plt.hist(pdf_dec_all['max_decel'][lambda x: x < 0], bins=65, density=True, label=r'$d_{max}^{SimRa}$', alpha=0.3)\n",
    "\n",
    "a, b, c, d = scipy.stats.nct.fit(pdf_dec_all['max_decel'][lambda x: x < 0]) # d_max -> nct (4 params)\n",
    "x = np.linspace(-2, 0, 1000)\n",
    "y = scipy.stats.nct.pdf(x, a, b, c, d)\n",
    "# NCT\n",
    "plt.plot(x, y, linewidth=3, label='NCT(' + r'$d_{max}; \\Phi^*$' + ')')\n",
    "plt.xlabel(r'$d_{max}$ in m/s²')\n",
    "plt.ylabel('Relative frequency')\n",
    "plt.vlines(-3, 0, 10, colors='r', linewidth=3, label=r'$v_{max}^{SUMO}$')\n",
    "plt.xlim(-3.1, 0)\n",
    "plt.ylim(0, 4.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"images/decel_max_all_rides.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# print(scipy.stats.nct.cdf(5.56, a0, b0, loc0, scale0))\n",
    "# print(scipy.stats.nct.cdf(25 / 3.6, a0, b0, loc0, scale0)) #\n",
    "#\n",
    "# print(scipy.stats.kstest(pdf_max_0['max_speed'], 'nct', args=(a0, b0, loc0, scale0)))\n",
    "# print(a0, b0, loc0, scale0)\n",
    "# print(scipy.stats.nct.ppf(0.05, a0, b0, loc0, scale0))\n",
    "# print(scipy.stats.nct.ppf(0.95, a0, b0, loc0, scale0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern'], 'size': 16})\n",
    "rc('text', usetex=True)\n",
    "plt.hist(pdf_max_0['max_speed'], bins=65, density=True, label=r'$v_{max}^{SimRa}$')\n",
    "\n",
    "a0, b0, loc0, scale0 = scipy.stats.nct.fit(pdf_max_0['max_speed'])\n",
    "x = np.linspace(0, 16, 1000)\n",
    "y0 = scipy.stats.nct.pdf(x, a0, b0, loc0, scale0)\n",
    "plt.plot(x, y0, linewidth=3, label='NCT(' + r'$v_{max}; \\Phi^*$' + ')')\n",
    "plt.xlabel(r'$v_{max}$ in m/s')\n",
    "plt.ylabel('Relative frequency')\n",
    "plt.vlines(5.56, 0, 4, colors='r', linewidth=3, label=r'$v_{max}^{SUMO}$')\n",
    "plt.xlim(1, 15)\n",
    "plt.ylim(0, 0.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"images/velo_max_v_avg_n.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "print(scipy.stats.nct.cdf(5.56, a0, b0, loc0, scale0))\n",
    "print(scipy.stats.nct.cdf(25 / 3.6, a0, b0, loc0, scale0)) #\n",
    "\n",
    "print(scipy.stats.kstest(pdf_max_0['max_speed'], 'nct', args=(a0, b0, loc0, scale0)))\n",
    "print(a0, b0, loc0, scale0)\n",
    "print(scipy.stats.nct.ppf(0.05, a0, b0, loc0, scale0))\n",
    "print(scipy.stats.nct.ppf(0.95, a0, b0, loc0, scale0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[20, 10])\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.grid()\n",
    "ax.xaxis.set_major_locator(ticker.LinearLocator(numticks=30))\n",
    "ax.set_ylabel('Rides')\n",
    "ax.set_xlabel('Speed (Km/h)')\n",
    "plt.xlim(0, 40)\n",
    "\n",
    "#plot_graph(pdf_avg_0['avg_speed'], \"Group 0\", False)\n",
    "plot_graph(pdf_max_0['max_speed'], \"Group 0\", False)\n",
    "\n",
    "#plot_graph(pdf_avg_1['avg_speed'], \"Group 1\", False)\n",
    "plot_graph(pdf_max_1['max_speed'], \"Group 1\", False)\n",
    "\n",
    "#plot_graph(pdf_avg_2['avg_speed'], \"Group 2\", False)\n",
    "plot_graph(pdf_max_2['max_speed'], \"Group 2\", False)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[20, 10])\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.grid()\n",
    "ax.xaxis.set_major_locator(ticker.LinearLocator(numticks=30))\n",
    "ax.set_ylabel('Rides')\n",
    "ax.set_xlabel('Accel (m/s²)')\n",
    "plt.xlim(0, 2)\n",
    "\n",
    "#plot_graph(pdf_all['max_accel'] / 3.6, \"All\", False)\n",
    "plot_graph(pdf_acc_0['max_accel'], \"Group 0\", False)\n",
    "plot_graph(pdf_acc_1['max_accel'], \"Group 1\", False)\n",
    "plot_graph(pdf_acc_2['max_accel'], \"Group 2\", False)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[20, 10])\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.grid()\n",
    "ax.xaxis.set_major_locator(ticker.LinearLocator(numticks=30))\n",
    "ax.set_ylabel('Rides')\n",
    "ax.set_xlabel('Accel (m/s²)')\n",
    "plt.xlim(0, 0.6)\n",
    "\n",
    "#plot_graph(pdf_all['max_accel'] / 3.6, \"All\", False)\n",
    "plot_graph(pdf_acc_0['max_accel'] / 3.6, \"Group 0\", False)\n",
    "plot_graph(pdf_acc_1['max_accel'] / 3.6, \"Group 1\", False)\n",
    "plot_graph(pdf_acc_2['max_accel'] / 3.6, \"Group 2\", False)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[20, 10])\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.grid()\n",
    "ax.xaxis.set_major_locator(ticker.LinearLocator(numticks=30))\n",
    "ax.set_ylabel('Rides')\n",
    "ax.set_xlabel('Decel (m/s²)')\n",
    "plt.xlim(-1.6, 0)\n",
    "\n",
    "plot_graph(pdf_all['max_decel'][lambda x: x < 0], \"All\", False)\n",
    "#plot_graph(pdf_dec_0['max_decel'] / 3.6, \"Group 0\", False)\n",
    "#plot_graph(pdf_dec_1['max_decel'] / 3.6, \"Group 1\", False)\n",
    "#plot_graph(pdf_dec_2['max_decel'] / 3.6, \"Group 2\", False)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DatabaseConnection() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "\n",
    "        SELECT two.fn, two.ts, two.ve FROM (\n",
    "        SELECT one.fn as fn, unnest(one.t) as ts, unnest(one.v) as ve FROM (\n",
    "        SELECT filename as fn, timestamps as t, distances as d, velos as v, (((ST_Points(geom::geometry))::json) -> 'coordinates') as pts from ride OFFSET 9 LIMIT 1\n",
    "        ) as one\n",
    "        ) as two WHERE two.ve != 'NaN' AND two.ve < 15 ORDER BY two.ts ASC\n",
    "\n",
    "    \"\"\")\n",
    "    objs_one = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_one = pd.DataFrame(objs_one, columns=['file', 'time', 'speed'])\n",
    "\n",
    "fig = plt.figure(figsize=[20, 10])\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.grid()\n",
    "ax.xaxis.set_major_locator(ticker.LinearLocator(numticks=30))\n",
    "ax.set_ylabel('Speed (Km/h)')\n",
    "ax.set_xlabel('Time (timestamp / 1e9 -> seconds)')\n",
    "#plt.xlim(0, 200)\n",
    "\n",
    "plt.plot(pdf_one['time'].map(lambda v: (v.value - pdf_one['time'][0].value) / 1e9), pdf_one['speed'] * 3.6, label=\"One ride\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DatabaseConnection() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "\n",
    "        SELECT three.fn, AVG(three.vf), AVG(three.vl) FROM (\n",
    "        SELECT two.fn as fn, unnest(two.ve[1:3]) as vf, unnest(two.ve[array_length(two.ve, 1) - 2:array_length(two.ve, 1)]) as vl FROM (\n",
    "        SELECT filename as fn, array_remove(velos, 'NaN') as ve FROM ride\n",
    "        ) as two\n",
    "        ) three GROUP BY three.fn\n",
    "\n",
    "    \"\"\")\n",
    "    objs_start_spd = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_start_spd = pd.DataFrame(objs_start_spd, columns=['file', 'avg_speed_e', 'avg_speed_l'])\n",
    "\n",
    "fig = plt.figure(figsize=[20, 10])\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.grid()\n",
    "ax.xaxis.set_major_locator(ticker.LinearLocator(numticks=30))\n",
    "ax.set_ylabel('Rides')\n",
    "ax.set_xlabel('AVG(First/Last 3) Speeds (m/s)')\n",
    "plt.xlim(0.01, 12)\n",
    "\n",
    "plot_graph(pdf_start_spd['avg_speed_e'], \"AVG(First 3)\", False)\n",
    "plot_graph(pdf_start_spd['avg_speed_l'], \"AVG(Last 3)\", False)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DatabaseConnection() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "\n",
    "        --SELECT two.fn, AVG(two.ve), MAX(two.ve),\n",
    "        --    AVG(two.a) filter (WHERE two.a >= 0 AND two.a != 'NaN'), MAX(two.a) filter (WHERE two.a >= 0 AND two.a != 'NaN'),\n",
    "        --    AVG(two.a) filter (WHERE two.a < 0 AND two.a != 'NaN'), MIN(two.a) filter (WHERE two.a < 0 AND two.a != 'NaN'),\n",
    "        --    CASE WHEN AVG(two.ve) < 4.3638 THEN 0 ELSE CASE WHEN AVG(two.ve) < 5.6694 THEN 1 ELSE 2 END END\n",
    "        --    FROM (\n",
    "        --        SELECT filename as fn, unnest(timestamps) as ts, unnest(velos) as ve, unnest(accels) as a FROM ride\n",
    "        --    ) as two WHERE two.ve > 0.2 AND two.ve != 'NaN' AND two.ve < 15 GROUP BY two.fn\n",
    "\n",
    "        SELECT two.fn, AVG(two.ve), MAX(two.ve), AVG(a1.accel), MAX(a1.accel), AVG(d1.accel), MIN(d1.accel), CASE WHEN AVG(two.ve) < 4.3638 THEN 0 ELSE CASE WHEN AVG(two.ve) < 5.6694 THEN 1 ELSE 2 END END FROM (\n",
    "        SELECT one.fn as fn, unnest(one.t) as ts, unnest(one.v) as ve FROM (\n",
    "        SELECT filename as fn, timestamps as t, distances as d, velos as v, (((ST_Points(geom::geometry))::json) -> 'coordinates') as pts from ride\n",
    "        ) as one\n",
    "        ) as two LEFT JOIN accels a1 ON (two.fn = a1.filename AND two.ts = a1.timestamp AND a1.accel >= 0)\n",
    "                 LEFT JOIN accels d1 ON (two.fn = d1.filename AND two.ts = d1.timestamp AND d1.accel < 0)\n",
    "                 WHERE two.ve > 0.2 AND two.ve != 'NaN' AND two.ve < 15 GROUP BY two.fn\n",
    "\n",
    "    \"\"\")\n",
    "    objs_corr = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyensae.graphhelper import Corrplot\n",
    "import docutils\n",
    "df_corr = pd.DataFrame(objs_corr, columns=['file', 'avg_speed', 'max_speed', 'avg_accel', 'max_accel', 'avg_decel', 'max_decel', 'group']).drop(columns=['file'])\n",
    "\n",
    "c = Corrplot(df_corr)\n",
    "c.plot(figsize=(20,10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "#pdf = pd.DataFrame(objs, columns=['file', 'velo']).query('velo > 0.2 and velo != \"NaN\" and velo < 15')\n",
    "\n",
    "#groupd = pdf.groupby('file').aggregate({'velo': np.average}).rename(columns={'velo': 'avg_speed'})\n",
    "\n",
    "#pdf = groupd #pdf.merge(groupd, how='inner', on='file')\n",
    "\n",
    "print(objs[0])\n",
    "\n",
    "# pdf_all = pd.DataFrame(objs, columns=['file', 'avg_speed', 'max_speed', 'max_accel', 'max_decel', 'group'])#.sort_values('avg_speed').reset_index()\n",
    "\n",
    "pdf_all = pd.DataFrame(objs, columns=['file', 'avg_speed', 'max_speed', 'max_accel', 'max_decel', 'group']).query('max_accel != \"NaN\"')\n",
    "\n",
    "pdf_avg_0 = pdf_all.query('group == 0')[['file', 'avg_speed']].sort_values('avg_speed').reset_index()\n",
    "pdf_max_0 = pdf_all.query('group == 0')[['file', 'max_speed']].sort_values('max_speed').reset_index()\n",
    "pdf_acc_0 = pdf_all.query('group == 0')[['file', 'max_accel']].sort_values('max_accel').reset_index()\n",
    "\n",
    "pdf_avg_1 = pdf_all.query('group == 1')[['file', 'avg_speed']].sort_values('avg_speed').reset_index()\n",
    "pdf_max_1 = pdf_all.query('group == 1')[['file', 'max_speed']].sort_values('max_speed').reset_index()\n",
    "pdf_acc_1 = pdf_all.query('group == 1')[['file', 'max_accel']].sort_values('max_accel').reset_index()\n",
    "\n",
    "pdf_avg_2 = pdf_all.query('group == 2')[['file', 'avg_speed']].sort_values('avg_speed').reset_index()\n",
    "pdf_max_2 = pdf_all.query('group == 2')[['file', 'max_speed']].sort_values('max_speed').reset_index()\n",
    "pdf_acc_2 = pdf_all.query('group == 2')[['file', 'max_accel']].sort_values('max_accel').reset_index()\n",
    "\n",
    "b1 = 15.71#3.6 * pdf_avg.iloc[int(0.25 * len(pdf_avg))]['avg_speed']\n",
    "b2 = 20.41#3.6 * pdf_avg.iloc[int(0.75 * len(pdf_avg))]['avg_speed']\n",
    "#c1 = 3.6 * pdf_max.iloc[int(0.25 * len(pdf_max))]['max_speed']\n",
    "#c2 = 3.6 * pdf_max.iloc[int(0.75 * len(pdf_max))]['max_speed']\n",
    "\n",
    "print(b1)\n",
    "print(b2)\n",
    "\n",
    "#pdf_g = pd.DataFrame([[1, 2, 3], [1, 5, 6], [2, 2, 4], [2, 5, 7]], columns=['a', 'b', 'c'])\n",
    "\n",
    "#groupd = pdf_g.groupby('a').aggregate({'b': np.average, 'c': np.average}).rename(columns={'b': 'b_avg', 'c': 'c_avg'})\n",
    "\n",
    "#print(groupd.query('a == 1'))\n",
    "\n",
    "#print(groupd)\n",
    "\n",
    "#print(pdf_g.merge(groupd, how='inner', on='a'))\n",
    "\n",
    "fig = plt.figure(figsize=[20, 10])\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.grid()\n",
    "ax.xaxis.set_major_locator(ticker.LinearLocator(numticks=30))\n",
    "ax.set_ylabel('Rides')\n",
    "#ax.set_xlabel('Speed (Km/h)')\n",
    "ax.set_xlabel('Accel (m/s²)')\n",
    "\n",
    "#ax.vlines([b1, b2], 0, 0.125)\n",
    "#ax.vlines([c1, c2], 0, 0.125)\n",
    "\n",
    "def plot_graph(pdf_local: pd.Series, vlines: bool):\n",
    "    mn, mx = plt.xlim()\n",
    "    n_bins = 200\n",
    "    plt.hist(pdf_local, n_bins, range=(mn, mx), density=False, histtype='step')\n",
    "    kde_xs = np.linspace(mn, mx, 200)\n",
    "    kde_avg = st.gaussian_kde(pdf_local)\n",
    "    plt.plot(kde_xs, ((mx - mn) / n_bins * len(pdf_local)) * kde_avg.pdf(kde_xs), label=\"PDF\")\n",
    "\n",
    "    if vlines:\n",
    "        ax.vlines([pdf_local.iloc[int(0.25 * len(pdf_local))], pdf_local.iloc[int(0.75 * len(pdf_local))]], 0, 0.125)\n",
    "\n",
    "\n",
    "#plt.hist(pdf_avg['avg_speed'] * 3.6, 200, density=True, histtype='step')\n",
    "#plt.hist(pdf_max['max_speed'] * 3.6, 200, density=True, histtype='step')\n",
    "#plt.plot(pdf.sort_values('avg_speed').reset_index()['avg_speed'])\n",
    "\n",
    "#plt.ylim([0, 10])\n",
    "\n",
    "#mn, mx = plt.xlim()\n",
    "#plt.xlim(mn, mx)\n",
    "plt.xlim(-0.1, 2)\n",
    "#kde_xs = np.linspace(mn, mx, 200)\n",
    "#kde_avg = st.gaussian_kde(pdf_avg['avg_speed'] * 3.6)\n",
    "#kde_max = st.gaussian_kde(pdf_max['max_speed'] * 3.6)\n",
    "#plt.plot(kde_xs, kde_avg.pdf(kde_xs), label=\"PDF\")\n",
    "#plt.plot(kde_xs, kde_max.pdf(kde_xs), label=\"PDF\")\n",
    "\n",
    "#plot_graph(pdf_avg_0['avg_speed'], False)\n",
    "#plot_graph(pdf_max_0['max_speed'], False)\n",
    "plot_graph(pdf_acc_0['max_accel'], False)\n",
    "\n",
    "#plot_graph(pdf_avg_1['avg_speed'], False)\n",
    "#plot_graph(pdf_max_1['max_speed'], False)\n",
    "plot_graph(pdf_acc_1['max_accel'], False)\n",
    "\n",
    "#plot_graph(pdf_avg_2['avg_speed'], False)\n",
    "#plot_graph(pdf_max_2['max_speed'], False)\n",
    "plot_graph(pdf_acc_2['max_accel'], False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DatabaseConnection() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "\n",
    "        SELECT COUNT(*) FROM ride\n",
    "\n",
    "    \"\"\")\n",
    "    allObjs = cur.fetchall()\n",
    "pdf_all_objs = pd.DataFrame(allObjs)\n",
    "print(pdf_all_objs.info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

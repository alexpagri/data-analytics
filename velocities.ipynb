{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from postgis.psycopg import register\n",
    "import project_path\n",
    "from db_importer.settings import *\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DatabaseConnection(object):\n",
    "    def __enter__(self):\n",
    "        self.conn = psycopg2.connect(f\"dbname='{DB_NAME}' user='{DB_USER}' password='{DB_PASSWORD}' host='{DB_HOST}' port='{DB_PORT}'\")\n",
    "        self.conn.autocommit = True\n",
    "\n",
    "        register(self.conn)\n",
    "        self.cur = self.conn.cursor()\n",
    "\n",
    "        return self.cur\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        if exc_tb is None:\n",
    "            self.conn.commit()\n",
    "            self.cur.close()\n",
    "            self.conn.close()\n",
    "        else:\n",
    "            self.conn.rollback()\n",
    "            self.cur.close()\n",
    "            self.conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval of v_max. Note: the median of the top 10 velos is calculated per ride to avoid outliers.\n",
    "\n",
    "conn = psycopg2.connect(f\"dbname='{DB_NAME}' user='{DB_USER}' password='{DB_PASSWORD}' host='{DB_HOST}' port='{DB_PORT}'\")\n",
    "conn.autocommit = True\n",
    "\n",
    "register(conn)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"SELECT filename, PERCENTILE_CONT(0.5) WITHIN GROUP(ORDER BY foo.velo) FROM(\n",
    "                SELECT clean.filename,\n",
    "                       clean.velo,\n",
    "                       rank() OVER (\n",
    "                           PARTITION BY filename\n",
    "                           ORDER BY velo DESC\n",
    "                           )\n",
    "                FROM\n",
    "                     (SELECT flat.filename filename,\n",
    "                             flat.velo velo\n",
    "                      FROM\n",
    "                           (SELECT ride.filename,\n",
    "                                   unnest(ride.velos) velo\n",
    "                           FROM ride) as flat\n",
    "                      WHERE NULLIF(flat.velo, 'NaN') IS NOT NULL) as clean) as foo \n",
    "                WHERE velo < 14 AND velo > 0.1 AND foo.rank <= 10 GROUP BY filename\"\"\")\n",
    "\n",
    "res = cur.fetchall()\n",
    "df = pd.DataFrame(res, columns=['filename', 'max_v'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import numpy as np\n",
    "from matplotlib import rc\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern'], 'size': 16})\n",
    "rc('text', usetex=True)\n",
    "plt.hist(df.max_v, bins=65, density=True, label=r'$v_{max}^{SimRa}$')\n",
    "\n",
    "a, b, loc, scale = scipy.stats.johnsonsu.fit(df.max_v)\n",
    "x = np.linspace(0, 16, 1000)\n",
    "y = scipy.stats.johnsonsu.pdf(x, a, b, loc, scale)\n",
    "plt.plot(x, y, linewidth=3, label='JSU(' + r'$v_{max}; \\Phi^*$' + ')')\n",
    "plt.xlabel(r'$v_{max}$ in m/s')\n",
    "plt.ylabel('Relative frequency')\n",
    "plt.vlines(5.56, 0, 4, colors='r', linewidth=3, label=r'$v_{max}^{SUMO}$')\n",
    "plt.xlim(1, 15)\n",
    "plt.ylim(0, 0.3)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"images/velo_max_v_avg_n.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "print(scipy.stats.johnsonsu.cdf(5.56, a, b, loc, scale))\n",
    "print(scipy.stats.johnsonsu.cdf(25/3.6, a, b, loc, scale)) # \n",
    "\n",
    "print(scipy.stats.kstest(df.max_v, 'johnsonsu', args=(a, b, loc, scale)))\n",
    "print(a, b, loc, scale)\n",
    "print(scipy.stats.johnsonsu.ppf(0.05, a, b, loc, scale))\n",
    "print(scipy.stats.johnsonsu.ppf(0.95, a, b, loc, scale))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting config\n",
    "columnwidth = 3.5\n",
    "textwidth = 3.5 * 2 + 0.25\n",
    "figsize = (columnwidth * 0.97, 1.75)\n",
    "params = {\n",
    "     \"pdf.fonttype\": 42,\n",
    "     \"font.family\": \"serif\",\n",
    "     \"font.serif\": \"Linux Libertine\",\n",
    "     \"font.sans-serif\": [],\n",
    "     \"font.monospace\": [],\n",
    "     # Make the legend/label fonts a little smaller\n",
    "     \"font.size\": 8,\n",
    "     \"axes.labelsize\": 8,\n",
    "     \"axes.titlesize\": 8,\n",
    "     \"legend.fontsize\": 6,\n",
    "     \"legend.title_fontsize\": 8,\n",
    "     \"xtick.labelsize\": 7,\n",
    "     \"ytick.labelsize\": 7,\n",
    "     \"figure.figsize\": figsize,\n",
    "     \"figure.autolayout\": True,\n",
    "     # save some space around figures when saving\n",
    "     \"savefig.bbox\": \"tight\",\n",
    "     \"savefig.pad_inches\": 0.025,\n",
    "}\n",
    "pdf_params = {\n",
    "     \"text.usetex\": True,\n",
    "#    \"pgf.texsystem\": \"pdflatex\",\n",
    "#    \"pgf.rcfonts\": False,\n",
    "#    \"pgf.preamble\": \"\\n\".join(\n",
    "#        [\n",
    "#            # put LaTeX preamble declarations here\n",
    "#            r\"\\usepackage[utf8x]{inputenc}\",\n",
    "#            r\"\\usepackage[T1]{fontenc}\",\n",
    "#        ]\n",
    "#    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.max_v, bins=50, density=True, label=r'$v_{max}^{SimRa}$')\n",
    "\n",
    "a, b, loc, scale = scipy.stats.johnsonsu.fit(df.max_v)\n",
    "x = np.linspace(0, 16, 1000)\n",
    "y = scipy.stats.johnsonsu.pdf(x, a, b, loc, scale)\n",
    "plt.plot(x, y, linewidth=1, label='JSU(' + r'$v_{max}; \\Phi^*$' + ')')\n",
    "plt.xlabel(r'$v_{max}$ in m/s')\n",
    "plt.ylabel('Rel. frequency')\n",
    "plt.vlines(5.56, 0, 4, colors='r', linewidth=1, label=r'$v_{max}^{SUMO}$')\n",
    "plt.xlim(1, 15)\n",
    "plt.ylim(0, 0.3)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "params.update(**pdf_params)\n",
    "plt.rcParams.update(params)\n",
    "plt.savefig(\"images/velo_max_v_avg_n.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "conn = psycopg2.connect(f\"dbname='ma_3' user='{DB_USER}' password='{DB_PASSWORD}' host='{DB_HOST}' port='{DB_PORT}'\")\n",
    "conn.autocommit = True\n",
    "\n",
    "register(conn)\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "cur.execute(\"\"\"SELECT filename, PERCENTILE_CONT(0.5) WITHIN GROUP(ORDER BY foo.velo) FROM(\n",
    "                SELECT clean.filename,\n",
    "                       clean.velo,\n",
    "                       rank() OVER (\n",
    "                           PARTITION BY filename\n",
    "                           ORDER BY velo DESC\n",
    "                           )\n",
    "                FROM\n",
    "                     (SELECT flat.filename filename,\n",
    "                             flat.velo velo\n",
    "                      FROM\n",
    "                           (SELECT ride.filename,\n",
    "                                   unnest(ride.velos) velo\n",
    "                           FROM ride) as flat\n",
    "                      WHERE NULLIF(flat.velo, 'NaN') IS NOT NULL) as clean) as foo \n",
    "                WHERE velo < 14 AND velo > 0.1 AND foo.rank <= 10 GROUP BY filename\"\"\")\n",
    "\n",
    "res = cur.fetchall()\n",
    "df_old = pd.DataFrame(res, columns=['filename', 'max_v'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "\n",
    "ecdf_old = ECDF(df_old['max_v'])\n",
    "plt.plot(ecdf_old.x, ecdf_old.y, label='buggy data')\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(f\"dbname='paper_1' user='{DB_USER}' password='{DB_PASSWORD}' host='{DB_HOST}' port='{DB_PORT}'\")\n",
    "conn.autocommit = True\n",
    "\n",
    "register(conn)\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "cur.execute(\"\"\"SELECT filename, PERCENTILE_CONT(0.5) WITHIN GROUP(ORDER BY foo.velo) FROM(\n",
    "                SELECT clean.filename,\n",
    "                       clean.velo,\n",
    "                       rank() OVER (\n",
    "                           PARTITION BY filename\n",
    "                           ORDER BY velo DESC\n",
    "                           )\n",
    "                FROM\n",
    "                     (SELECT flat.filename filename,\n",
    "                             flat.velo velo\n",
    "                      FROM\n",
    "                           (SELECT ride.filename,\n",
    "                                   unnest(ride.velos) velo\n",
    "                           FROM ride) as flat\n",
    "                      WHERE NULLIF(flat.velo, 'NaN') IS NOT NULL) as clean) as foo \n",
    "                WHERE velo < 14 AND velo > 0.1 AND foo.rank <= 10 GROUP BY filename\"\"\")\n",
    "\n",
    "res = cur.fetchall()\n",
    "df_new = pd.DataFrame(res, columns=['filename', 'max_v'])\n",
    "\n",
    "\n",
    "ecdf_new = ECDF(df_new['max_v'])\n",
    "plt.plot(ecdf_new.x, ecdf_new.y, label='clean data')\n",
    "\n",
    "df_all = df_old.append(df_new, ignore_index=True)\n",
    "ecdf_all = ECDF(df_all['max_v'])\n",
    "plt.plot(ecdf_all.x, ecdf_all.y, label='all data')\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scipy.stats.ks_2samp(df_old.max_v, df_new.max_v))\n",
    "print(scipy.stats.ks_2samp(df_old.max_v, df_all.max_v))\n",
    "print(scipy.stats.ks_2samp(df_new.max_v, df_all.max_v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 16, 1000)\n",
    "y = scipy.stats.johnsonsu.pdf(x, a, b, loc, scale)\n",
    "plt.plot(x, y, linewidth=3, label='JSU(' + r'$v_{max}; \\Phi^*$' + ')')\n",
    "plt.xlabel(r'$v_{max}$ in m/s')\n",
    "plt.ylabel('Relative frequency')\n",
    "plt.vlines(5.56, 0, 4, colors='r', linewidth=3, label=r'$v_{max}^{SUMO}$')\n",
    "plt.xlim(1, 15)\n",
    "plt.ylim(0, 0.3)\n",
    "y1 = scipy.stats.johnsonsu.pdf(x,-0.8220390816645484, 2.613315502965807, 5.997224430646749, 3.733741887318888)\n",
    "plt.plot(x, y1, linewidth=3, label='JSUalt(' + r'$v_{max}; \\Phi^*$' + ')')\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best distribution for v_max\n",
    "\n",
    "list_of_dists = ['powernorm','norm','exponnorm','beta','betaprime','bradford','burr','burr12','cauchy','chi','chi2','cosine','dgamma','dweibull','erlang','expon','exponnorm','exponweib','exponpow','f','fatiguelife','fisk','foldcauchy','foldnorm','frechet_r','frechet_l','genlogistic','genpareto','gennorm','genexpon','genextreme','gausshyper','gamma','gengamma','genhalflogistic','gilbrat','gompertz','gumbel_r','gumbel_l','halfcauchy','halflogistic','halfnorm','halfgennorm','hypsecant','invgamma','invgauss','invweibull','johnsonsb','johnsonsu','kstwobign','laplace','levy','levy_l','logistic','loggamma','loglaplace','lognorm','lomax','maxwell','mielke','nakagami','ncx2','ncf','nct','norm','pareto','pearson3','powerlaw','powerlognorm','powernorm','rdist','reciprocal','rayleigh','rice','recipinvgauss','semicircular','t','triang','truncexpon','truncnorm','tukeylambda','uniform','vonmises','vonmises_line','wald','weibull_min','weibull_max']\n",
    "\n",
    "results=[]\n",
    "for i in list_of_dists:\n",
    "    dist = getattr(scipy.stats, i)\n",
    "    param = dist.fit(df.max_v)\n",
    "    a = scipy.stats.kstest(df.max_v, i, args=param)\n",
    "    results.append((i,a[0],a[1]))\n",
    "    \n",
    "    \n",
    "results.sort(key=lambda x:float(x[2]), reverse=True)\n",
    "for j in results:\n",
    "    print(\"{}: statistic={}, pvalue={}\".format(j[0], j[1], j[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show correlation between a_max and v_max (v_max = again Median of top 10 per ride)\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "with DatabaseConnection() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "    SELECT a.filename, avg_velo, max_a\n",
    "FROM (SELECT filename, avg(foo.velo) avg_velo\n",
    "      FROM (\n",
    "               SELECT clean.filename,\n",
    "                      clean.velo,\n",
    "                      rank() OVER (\n",
    "                          PARTITION BY filename\n",
    "                          ORDER BY velo DESC\n",
    "                          )\n",
    "               FROM (SELECT flat.filename filename,\n",
    "                            flat.velo     velo\n",
    "                     FROM (SELECT ride.filename,\n",
    "                                  unnest(ride.velos) velo\n",
    "                           FROM ride) as flat\n",
    "                     WHERE NULLIF(flat.velo, 'NaN') IS NOT NULL) as clean) as foo\n",
    "      WHERE velo < 14\n",
    "        AND foo.rank <= 10\n",
    "      GROUP BY filename) a\n",
    "         INNER JOIN\n",
    "     (select accels.filename, max(accel) max_a\n",
    "      from accels\n",
    "      where type = 'a'\n",
    "      group by seg_id, accels.filename\n",
    "      having max(accel) < 2\n",
    "         and sum(dist) < 350\n",
    "         and sum(dist) > 20\n",
    "         and min(velo) < 1) b\n",
    "     ON a.filename = b.filename\n",
    "    \"\"\")\n",
    "    res = cur.fetchall()\n",
    "    df = pd.DataFrame(res, columns=['filename', 'max_v', 'max_a'])\n",
    "    df['ln_max_v'] = df.apply(lambda x: math.log(x['max_v']), axis = 1) \n",
    "    df['ln_max_a'] = df.apply(lambda x: math.log(x['max_a']), axis = 1) \n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    plt.scatter(df.max_v, df.max_a, marker='.', s=0.2,)\n",
    "    plt.xlabel(r'$v_{max}$ in m/s')\n",
    "    plt.ylabel(r'$a_{max}$ in m/s²')\n",
    "\n",
    "    plt.savefig(\"images/acc_vs_velo.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "slope, intercept, r_value, p_value, std_err = linregress(df.max_v, df.max_a)\n",
    "print(r_value**2)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = linregress(df.ln_max_v, df.ln_max_a)\n",
    "print(r_value**2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
